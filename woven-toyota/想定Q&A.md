# 想定質問と回答集 (Q&A) - ウーブン・バイ・トヨタ案件

本資料は、商談や面接で現場エンジニアから聞かれる可能性が高い技術的な質問と、それに対する回答をまとめたものです。

## 1. インフラアーキテクチャ全般

### Q1-1: なぜEKSを選んだのですか？ECSではダメだった理由を教えてください。

**A**: EKSを選定した主な理由は以下の通りです：

1. **標準化**: KubernetesはCNCF標準で、ベンダーロックインを回避できます。将来的にマルチクラウド展開や環境移行を検討する際に柔軟性があります。

2. **エコシステム**: Helm、Istio、Prometheus、Argo CD等、豊富なKubernetesエコシステムを活用できます。ECSではこれらのツールが利用できません。

3. **スケーラビリティ**: Horizontal Pod Autoscaler (HPA)、Cluster Autoscaler等、柔軟なスケーリング機能があります。

4. **学習コストと汎用性**: Kubernetesスキルは汎用的で、他の環境でも活用可能です。

ECSもシンプルで運用負荷が低いというメリットがありますが、今回の案件では標準化とエコシステムの活用を優先しました。

---

### Q1-2: なぜマルチAZ構成にしたのですか？コスト削減のためにシングルAZではダメですか？

**A**: マルチAZ構成を採用した理由は以下の通りです：

1. **高可用性**: 単一AZ障害時でもサービスを継続できます。スマートシティ向けのサービスは可用性が重要です。

2. **AWS Well-Architected Framework**: AWSが推奨するベストプラクティスに準拠しています。

3. **データベースの高可用性**: RDS Multi-AZやAurora Multi-AZを使用する場合、マルチAZ構成が前提となります。

4. **ロードバランシング**: Application Load BalancerでマルチAZにトラフィックを分散できます。

コスト面では、シングルAZ構成の方が確かに安価ですが、可用性のリスクを考慮すると、マルチAZ構成の方が長期的にはリスクコストが低いと判断しました。

---

### Q1-3: プライベートサブネットにアプリケーションを配置する理由を教えてください。パブリックサブネットではダメですか？

**A**: プライベートサブネットにアプリケーションを配置する理由は以下の通りです：

1. **セキュリティ**: インターネットからの直接アクセスを遮断し、セキュリティリスクを低減します。Application Load Balancer (ALB) をパブリックサブネットに配置し、ALB経由でのみアクセス可能にします。

2. **ネットワークセグメンテーション**: パブリックサブネットとプライベートサブネットでネットワークを分離し、セキュリティ境界を明確にします。

3. **ベストプラクティス**: AWS Well-Architected Frameworkのセキュリティの柱で推奨されている構成です。

4. **コンプライアンス**: セキュリティ要件やコンプライアンス要件を満たすための基本的な構成です。

パブリックサブネットに配置すると、セキュリティグループのみに依存することになり、誤設定のリスクが高まります。

---

## 2. Kubernetes (EKS) 関連

### Q2-1: EKSクラスターのスケーリング戦略を教えてください。

**A**: EKSクラスターのスケーリング戦略は以下の通りです：

1. **Podレベルのスケーリング**: Horizontal Pod Autoscaler (HPA) を使用し、CPU/メモリ使用率に基づいてPod数を自動スケーリングします。

2. **Nodeレベルのスケーリング**: Cluster Autoscalerを使用し、Podのスケジュール不可状態に応じてNodeを自動追加・削除します。

3. **Vertical Pod Autoscaler (VPA)**: リソース要求の最適化を行い、リソースの過不足を調整します。

4. **Karpenter**: オプションとして、Karpenterを使用することで、より迅速なスケーリングとコスト最適化が可能です。

5. **Spot Instances**: 開発環境やバッチ処理にはSpot Instancesを使用し、コストを最適化します。

---

### Q2-2: Ingress ControllerとしてAWS Load Balancer Controllerを選んだ理由を教えてください。NGINX Ingress Controllerではダメですか？

**A**: AWS Load Balancer Controllerを選定した理由は以下の通りです：

1. **AWSネイティブ**: Application Load Balancer (ALB) を直接作成・管理でき、AWSサービスとの統合がシームレスです。

2. **コスト**: ALBを直接使用するため、追加のEC2インスタンス（NGINX Ingress Controller用）が不要で、コストを削減できます。

3. **機能**: ALBの機能（WAF統合、Path-based routing、Host-based routing等）を直接活用できます。

4. **AWS Certificate Manager (ACM)**: ALBでHTTPS終端を行い、ACMの証明書を直接使用できます。

NGINX Ingress Controllerも強力で柔軟性が高いですが、今回はAWSネイティブな構成を優先しました。要件によってはNGINX Ingress Controllerも選択肢として検討可能です。

---

### Q2-3: KubernetesのNamespace設計について、なぜこのように分けましたか？

**A**: Namespace設計の理由は以下の通りです：

1. **production**: 本番環境のリソースを分離し、誤操作や設定漏れを防止します。

2. **staging**: ステージング環境で本番環境に近い環境を構築し、本番デプロイ前の検証を行います。

3. **development**: 開発環境で開発者が自由に実験できる環境を提供します。

4. **data-pipeline**: データ処理パイプライン専用のNamespaceで、リソースクォータやNetwork Policyを個別に設定できます。

この分離により、環境間の干渉を防ぎ、セキュリティと運用性を向上させます。

---

## 3. CI/CDパイプライン関連

### Q3-1: なぜGitHub Actionsを選んだのですか？JenkinsやCircleCIではダメですか？

**A**: GitHub Actionsを選定した理由は以下の通りです：

1. **統合性**: GitHubリポジトリと同一プラットフォームで、シームレスに統合できます。Pull RequestとCI/CDが密に連携できます。

2. **運用負荷**: マネージドサービスで、インフラ管理が不要です。Jenkinsのようなセルフホスト型と比較して運用負荷が低いです。

3. **コスト**: プライベートリポジトリも月2,000分の無料枠があり、小規模チームではコストを抑えられます。

4. **設定の簡潔性**: YAMLファイルベースで、Gitリポジトリでバージョン管理が容易です。

Jenkinsは柔軟性が高いですが、セルフホスト型で運用負荷が高く、設定が複雑です。CircleCIも強力ですが、GitHub Actionsと比較してコストが高くなります。

---

### Q3-2: CI/CDパイプラインのデプロイ戦略について、なぜこの段階的なデプロイフローにしたのですか？

**A**: 段階的なデプロイフローを採用した理由は以下の通りです：

1. **リスク低減**: Development → Staging → Productionの順で段階的にデプロイすることで、問題を早期に発見できます。

2. **品質保証**: 各環境でテストを実施し、本番環境への影響を最小化します。

3. **ロールバック**: 各段階で問題が発生した場合、前の環境にロールバックできます。

4. **承認プロセス**: Productionデプロイには手動承認を設けることで、重要な変更を確実に確認します。

この段階的なフローにより、本番環境への影響を最小化し、システムの安定性を確保します。

---

### Q3-3: コンテナイメージの脆弱性スキャンはどのように実施していますか？

**A**: コンテナイメージの脆弱性スキャンは以下のように実施します：

1. **ECR統合スキャン**: Amazon ECRのイメージスキャン機能を使用し、イメージプッシュ時に自動で脆弱性スキャンを実施します。

2. **CI/CDパイプラインでのスキャン**: GitHub ActionsでTrivyやSnyk等のツールを使用し、ビルド時に脆弱性スキャンを実施します。

3. **ブロック機能**: 重大度が高い脆弱性（Critical、High）が検出された場合、デプロイをブロックします。

4. **定期スキャン**: 既存のイメージに対して定期スキャンを実施し、新たに発見された脆弱性を検出します。

5. **アラート**: 脆弱性検出時はSlackやPagerDutyにアラートを通知します。

---

## 4. データ処理パイプライン関連

### Q4-1: データ処理パイプラインのオーケストレーションとして、なぜAirflowを選んだのですか？Step Functionsではダメですか？

**A**: Airflowを選定した理由は以下の通りです：

1. **柔軟性**: PythonでDAG（Directed Acyclic Graph）を定義でき、複雑なワークフローを柔軟に記述できます。

2. **Kubernetes統合**: KubernetesExecutorにより、Kubernetesクラスターのリソースを活用でき、スケーラビリティが高いです。

3. **豊富なオペレーター**: AWS、Kubernetes、データベース等、多様なオペレーターが利用可能です。

4. **UI**: Web UIでワークフローの実行状況を可視化でき、デバッグが容易です。

5. **コミュニティ**: オープンソースで、コミュニティが大きく活発です。

Step FunctionsもAWSネイティブで統合しやすいですが、Kubernetes環境との統合がAirflowほど柔軟ではありません。ただし、AWSサービス中心のワークフローではStep Functionsも選択肢として検討可能です。

---

### Q4-2: Databricksの使用は決定していますか？それとも検討段階ですか？

**A**: 現時点ではDatabricksの使用は検討段階です。使用する場合の想定用途は以下の通りです：

1. **大規模データ処理**: Sparkベースの大規模データ処理が必要な場合

2. **統合ML機能**: DatabricksのML機能（MLflow、Feature Store等）を活用する場合

3. **ノートブック環境**: データサイエンティストが使用するノートブック環境が必要な場合

ただし、まずはAWSネイティブな構成（SageMaker、EMR等）で要件を満たせるか検討し、必要に応じてDatabricksを導入する方針です。

実際の使用状況や要件に応じて、商談の場で詳細を確認したいと思います。

---

### Q4-3: データレイク（S3）のデータ階層構造はどのように設計していますか？

**A**: S3データレイクのデータ階層構造は以下のように設計します：

```
s3://data-lake-bucket/
├── raw/              # 生データ（未加工）
│   ├── year=2026/
│   │   ├── month=01/
│   │   └── month=02/
├── processed/        # 処理済みデータ
│   ├── year=2026/
│   │   ├── month=01/
│   │   └── month=02/
├── curated/          # キュレート済みデータ（分析用）
│   ├── year=2026/
│   │   ├── month=01/
│   │   └── month=02/
└── archive/          # アーカイブデータ（Glacier）
    ├── year=2025/
    └── year=2024/
```

この階層構造により、データのライフサイクルを管理し、コストを最適化します。S3 Lifecycle Policiesを使用して、古いデータを自動でGlacierにアーカイブします。

---

## 5. セキュリティ関連

### Q5-1: Secrets管理はどのように実施していますか？

**A**: Secrets管理は以下のように実施します：

1. **AWS Secrets Manager**: アプリケーションシークレット、データベース認証情報等を管理します。自動ローテーション機能を活用します。

2. **Kubernetes Secrets**: コンテナ環境用のSecretsを管理します。暗号化済み（etcd暗号化）で保存します。

3. **IAM Roles for Service Accounts (IRSA)**: EKSでIRSAを使用し、PodにAWS IAMロールを割り当てます。SecretsをKubernetes Secretsで管理する必要がなくなります。

4. **アクセス制御**: IAMポリシーでSecretsへのアクセスを制御し、最小権限の原則を適用します。

5. **監査**: CloudTrailでSecretsへのアクセスをログ記録し、監査を実施します。

---

### Q5-2: ネットワークセキュリティはどのように確保していますか？

**A**: ネットワークセキュリティは以下のように確保します：

1. **VPC設計**: パブリックサブネットとプライベートサブネットでネットワークを分離します。

2. **Security Groups**: インスタンスレベルのファイアウォールで、最小限のポートのみ開放します。

3. **Network ACLs**: サブネットレベルのファイアウォールで、追加の防御層を提供します。

4. **Kubernetes Network Policies**: Pod間の通信を制御し、最小権限の原則を適用します。

5. **WAF (Web Application Firewall)**: Application Load Balancer前段でWAFを配置し、アプリケーションレイヤーの攻撃を防御します。

6. **VPC Flow Logs**: ネットワークトラフィックをログ記録し、異常検出を実施します。

---

### Q5-3: コンテナのセキュリティはどのように確保していますか？

**A**: コンテナのセキュリティは以下のように確保します：

1. **イメージスキャン**: ECR統合スキャン、Trivy等でイメージの脆弱性をスキャンします。

2. **Pod Security Standards**: Kubernetes Podセキュリティ標準を適用し、セキュアなPod設定を強制します。

3. **最小権限の原則**: Service Account、RBAC、IRSAを使用し、最小限の権限のみ付与します。

4. **非rootユーザー**: コンテナイメージは非rootユーザーで実行するように設定します。

5. **リソース制限**: CPU/メモリのリソース制限を設定し、DoS攻撃を緩和します。

6. **Secrets管理**: Secrets Manager、Kubernetes Secretsを使用し、Secretsを適切に管理します。

---

## 6. 監視・ロギング関連

### Q6-1: なぜPrometheus + Grafanaを使用するのですか？CloudWatchだけではダメですか？

**A**: Prometheus + Grafanaを採用する理由は以下の通りです：

1. **Kubernetes標準**: PrometheusはKubernetesのメトリクス収集に標準的に使用されます。

2. **柔軟なクエリ**: PromQLにより、柔軟なクエリが可能です。

3. **豊富な可視化**: Grafanaにより、高機能なダッシュボードを作成できます。

4. **オープンソース**: コストがかからず、カスタマイズ可能です。

5. **エコシステム**: 豊富なエクスポーター（Node Exporter、cAdvisor等）が利用可能です。

CloudWatchはAWSリソースの監視には優れていますが、Kubernetesメトリクスの収集にはPrometheusほど柔軟ではありません。両方を使用し、CloudWatchでAWSリソースを監視し、PrometheusでKubernetesメトリクスを監視するハイブリッド構成を採用します。

---

### Q6-2: ログ管理はどのように実施していますか？

**A**: ログ管理は以下のように実施します：

1. **Fluent Bit**: Kubernetesクラスター内でFluent BitをDaemonSetとしてデプロイし、コンテナログを収集します。

2. **CloudWatch Logs**: Fluent BitからCloudWatch Logsにログを送信し、統合ログ管理を実施します。

3. **Amazon OpenSearch Service**: 検索・分析が必要な場合は、OpenSearch Serviceにログを送信します。

4. **構造化ログ**: JSON形式で構造化ログを出力し、検索・分析を容易にします。

5. **ログ保持期間**: 本番環境は30日、開発/ステージング環境は7日を想定していますが、要件に応じて調整します。

6. **ログアラート**: CloudWatch Logs Insightsでログを分析し、異常検出時にアラートを通知します。

---

### Q6-3: アラート設計はどのように実施していますか？

**A**: アラート設計は以下のように実施します：

1. **SLO/SLI定義**: 可用性、レイテンシ、エラー率等のSLO/SLIを定義します。

2. **アラートルール**: CloudWatch Alarms、Prometheus Alertmanagerでアラートルールを設定します。

3. **重大度分類**: Critical、High、Medium、Lowの4段階で重大度を分類します。

4. **通知チャネル**: Slack、PagerDuty、Email等、複数の通知チャネルを使用します。

5. **エスカレーションポリシー**: 重大度に応じたエスカレーションポリシーを定義します。

6. **アラート疲れ対策**: アラートの閾値や条件を適切に設定し、不要なアラートを削減します。

---

## 7. コスト最適化関連

### Q7-1: コスト最適化の戦略を教えてください。

**A**: コスト最適化の戦略は以下の通りです：

1. **Right Sizing**: CloudWatchメトリクスでリソース使用率を監視し、インスタンスサイズを最適化します。

2. **Reserved Instances**: 本番環境では1年/3年のReserved Instancesを検討します。

3. **Spot Instances**: 開発環境やバッチ処理にはSpot Instancesを使用し、コストを削減します。

4. **S3 Intelligent-Tiering**: S3 Intelligent-Tieringを使用し、アクセスパターンに応じた自動階層化を実施します。

5. **S3 Lifecycle Policies**: 古いデータを自動でGlacierにアーカイブし、コストを削減します。

6. **Auto Scaling**: Horizontal Pod Autoscaler、Cluster Autoscalerを使用し、需要に応じてリソースを自動スケーリングします。

7. **タグ戦略**: プロジェクト、環境、コストセンター別にタグ付けし、コスト配分を明確にします。

---

## 8. 災害復旧・バックアップ関連

### Q8-1: バックアップ戦略を教えてください。

**A**: バックアップ戦略は以下の通りです：

1. **RDS/Aurora**: 自動スナップショットを1日1回、7日間保持します。マルチAZ構成で高可用性を確保します。

2. **S3**: バージョニングとクロスリージョンレプリケーションを有効化します。

3. **EBS**: EBSスナップショットを定期取得します。

4. **Kubernetesリソース**: etcdスナップショットを定期取得します。

5. **Terraform状態**: Terraform状態ファイルはS3に保存し、バージョニングを有効化します。

6. **バックアップテスト**: 定期的にバックアップのリストアテストを実施します。

---

### Q8-2: 災害復旧計画はありますか？

**A**: 災害復旧計画は以下のように策定します：

1. **RTO/RPO定義**: Recovery Time Objective (RTO) とRecovery Point Objective (RPO) を定義します。

2. **DRサイト**: 別リージョンへの災害時復旧手順を文書化します。

3. **バックアップ戦略**: 上記のバックアップ戦略に基づき、データの復旧を可能にします。

4. **IaC活用**: Terraform等のIaCを使用し、災害時にも迅速にインフラを再構築できるようにします。

5. **定期テスト**: 定期的にDRテストを実施し、復旧手順を検証します。

詳細なRTO/RPOの目標値については、商談の場で確認したいと思います。

---

## 9. その他

### Q9-1: この設計で懸念点やリスクはありますか？

**A**: 以下の点が懸念点・リスクとして考えられます：

1. **学習コスト**: Kubernetes、Terraform等の学習コストが高い可能性があります。段階的な導入とトレーニングが必要です。

2. **運用負荷**: 初期構築後の運用負荷が高い可能性があります。自動化とマネージドサービスの活用で軽減します。

3. **コスト**: マルチAZ構成や高可用性構成により、コストが高くなる可能性があります。コスト最適化戦略で対応します。

4. **複雑性**: システムが複雑になりがちです。ドキュメント化と標準化で対応します。

5. **ベンダーロックイン**: AWSサービスに依存する部分がありますが、オープンスタンダード（Kubernetes等）の採用で軽減します。

これらの懸念点については、段階的な導入と継続的な改善で対応していきます。

---

### Q9-2: 今後の拡張性はどう考えていますか？

**A**: 今後の拡張性について、以下の点を考慮しています：

1. **マルチクラウド対応**: Terraform等のマルチクラウド対応ツールを採用し、将来的なマルチクラウド展開に対応可能にしています。

2. **スケーラビリティ**: Kubernetesの自動スケーリング機能により、需要の増加に対応可能です。

3. **エッジコンピューティング**: IoTデバイスとの連携拡張を考慮し、AWS IoT Greengrass等の検討が可能です。

4. **AI/ML機能の強化**: SageMaker、Kubeflow等の導入により、より高度なML機能を追加可能です。

5. **モジュール化**: IaCのモジュール化により、新機能の追加が容易です。

具体的な拡張計画については、商談の場で確認したいと思います。

---

## 10. 商談で確認したい事項

### Q10-1: 確認したい技術的な詳細事項

1. **既存インフラの状況**: 現在のインフラ構成、使用しているツール、課題等

2. **スケーリング要件**: ピーク時のトラフィック、データ量、ユーザー数等

3. **セキュリティ要件**: コンプライアンス要件、セキュリティポリシー等

4. **コスト制約**: 予算、コスト最適化の優先度等

5. **運用体制**: On-call体制、運用チームの規模等

6. **データ処理要件**: データ量、処理頻度、リアルタイム性等

7. **SLO/SLI**: 可用性、レイテンシ、エラー率の目標値等

8. **災害復旧要件**: RTO/RPOの目標値、DRテストの頻度等

---

## 参考資料

- AWS Well-Architected Framework
- Kubernetes Best Practices
- Terraform Best Practices
- CI/CD Best Practices
- Site Reliability Engineering (SRE) Practices
